{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e006969c-76b5-4da3-a5f7-a73ee350095d",
   "metadata": {},
   "source": [
    "# Cross-Fitting and $p$-Value Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3beca65-ea0e-40d2-b37a-e319c7f87623",
   "metadata": {},
   "source": [
    "In this tutorial, we will demonstrate how to implement cross-fitting and $p$-value combination by using `Crosser`. The `Crosser` object also provides a user-friendly interface to conduct nested cross-validation (CV) that results in a more stable result under small sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c736b034-1b11-4be5-8902-d6e32fbc6eba",
   "metadata": {},
   "source": [
    "We will use the `diabetes` data set again for demonstration. The following code prepares the data for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b99e3c-5a0c-4705-8b10-50d70bc1164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = datasets.load_diabetes(\n",
    "    return_X_y = True,\n",
    "    as_frame = True,\n",
    "    scaled = False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size = .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ff334-bb0b-4e45-a258-37b23383da48",
   "metadata": {},
   "source": [
    "## `Crosser` Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38787034-bd1e-4e61-b753-71f4a3e68d9f",
   "metadata": {},
   "source": [
    "Briefly speaking, `Crosser` is an object that can conduct nested cross-validation (CV) to improve the stability of learning result. Suppose we have split the a data set $Z$ into 5 folds, say $Z^{(1)}, Z^{(2)}, Z^{(3)}, Z^{(4)}, Z^{(5)}$. For each $k \\in \\{1,2,3,4,5\\}$, we set $Z_\\text{train}^{(k)} = \\{Z_l\\}_{l \\neq k}$ and $Z_\\text{test}^{(k)} = \\{Z_k\\}$. Then $Z_\\text{train}^{(k)}$ is used to train $\\widehat{f}^{(k)}$ and $Z_\\text{test}^{(k)}$ is used to evaluate the performance of $\\widehat{f}^{(k)}$. Note that when training $\\widehat{f}^{(k)}$ an inner CV loop may be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6bfe6-8112-46fa-a988-033e92496995",
   "metadata": {},
   "source": [
    "To understand `Crosser` more concretely, let use create a cross-validator via `KFold`. The cv can help us to create the training and test indices for the 5-fold CV. An important thing here is that a specific `random_state` must be given. Otherwise, `sial` may yield a wrong result when making statistical inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bff9214-e753-4044-b8c8-5f43f6149c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(\n",
    "    n_splits = 5,\n",
    "    shuffle = True,\n",
    "    random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f147150-b257-4edd-a02a-ad293a654796",
   "metadata": {},
   "source": [
    "Now we initialize a `Crosser` object. When initializing, an estimator and a cross-validator must be given. The estimator can be a usual `scikit-learn` estimator or a `GridSearchCV` object as in this example. The `GridSearchCV` object runs an inner CV loop to find an optimal tuning parameter value for each $\\widehat{f}^{(k)}$. The `fit` method trains $\\widehat{f}^{(1)}$, $\\widehat{f}^{(2)}$, ..,$\\widehat{f}^{(5)}$ on their corresponding training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083121c3-0775-4377-bea2-af014742a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sial import Crosser\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "learner = Crosser(\n",
    "    GridSearchCV(\n",
    "        estimator = RandomForestRegressor(), \n",
    "        param_grid = {\n",
    "            \"max_features\": [3, 6, 9]}),\n",
    "    cv = cv)\n",
    "_ = learner.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21aa3a2-666d-4f0f-82f4-5741c95cf41b",
   "metadata": {},
   "source": [
    "To extract the trained estimators, we can use the `estimator_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367bf6c5-78b0-4e75-ac26-f5cf27de3af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learner.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5e0de-3d88-4637-8345-ec796cb73bd9",
   "metadata": {},
   "source": [
    "The overall performances of these trained estimators can be shown by the `summarize` method. Three types of error scores are reported. The `val_score` is the validation error extracted from the `GridSearchCV`. The `train_score` and `test_score` are calculated by `Crosser`. By default, regression tasks use `r2` scorer and classification tasks uses `accuracy`. The scoring method can be explicitly specified via the `scoring` argument when initializing a `Crosser`. Availabe scoring methods can be found [here](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8498f8-c0f6-46c1-bb74-928760ca469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosser Summary (cross_fit=True, combine=False)\n",
      " + Estimator: GridSearchCV\n",
      " + Cross-Validator: KFold (n_folds=5, n_repeats=1)\n",
      " + Train/Test Scorer: R2 (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repeat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438521</td>\n",
       "      <td>0.923787</td>\n",
       "      <td>0.425175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        val_score  train_score  test_score\n",
       "repeat                                    \n",
       "0        0.438521     0.923787    0.425175"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bbaaa-3024-430b-a396-f26bda60b388",
   "metadata": {},
   "source": [
    "By default, the `summarize` method averages the error scores. It is also possible to show the error scores for each fold by setting `cross_fit = False`. We can see that the test errors are quite different across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136d2687-f98f-4007-9197-68b506507657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosser Summary (cross_fit=False, combine=False)\n",
      " + Estimator: GridSearchCV\n",
      " + Cross-Validator: KFold (n_folds=5, n_repeats=1)\n",
      " + Train/Test Scorer: R2 (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>repeat</th>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.480746</td>\n",
       "      <td>0.928988</td>\n",
       "      <td>0.392548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.467891</td>\n",
       "      <td>0.925515</td>\n",
       "      <td>0.300636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <td>0.418019</td>\n",
       "      <td>0.922168</td>\n",
       "      <td>0.445106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>0.421659</td>\n",
       "      <td>0.921233</td>\n",
       "      <td>0.452291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <td>0.404291</td>\n",
       "      <td>0.921029</td>\n",
       "      <td>0.535294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   val_score  train_score  test_score\n",
       "split repeat fold                                    \n",
       "0     0      0      0.480746     0.928988    0.392548\n",
       "1     0      1      0.467891     0.925515    0.300636\n",
       "2     0      2      0.418019     0.922168    0.445106\n",
       "3     0      3      0.421659     0.921233    0.452291\n",
       "4     0      4      0.404291     0.921029    0.535294"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summarize(\n",
    "    cross_fit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f77a2-cf64-4d36-8fe9-1bfd3b49e127",
   "metadata": {},
   "source": [
    "The `Crosser` also has a `predict` method for prediction. For a regressor, by default, it makes predictions by averaging the predictions made by all the trained estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc49f9e9-6de9-4b3a-a46a-c04ba22f1ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.688,  80.214, 158.082, 192.374, 119.66 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict(\n",
    "    X.iloc[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d277187-aa1e-48f4-ac8f-7bbaa088583d",
   "metadata": {},
   "source": [
    "When the estimator is a classifier, the prediction is based on majority voting. If we hope to make predictions based on a model trained on specific split, the argument `split` can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37ad3f0-5686-4ff9-a9f9-1070988e6f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.86,  78.37, 156.75, 201.22, 105.67])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.predict(\n",
    "    X.iloc[:5,:],\n",
    "    split = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8ca42f-88a7-4060-8ec3-705623ab04bc",
   "metadata": {},
   "source": [
    "## Inference with Cross-Fitting via `Crosser`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca71ad0-7fa1-47fc-bdc8-ea2f6a047871",
   "metadata": {},
   "source": [
    "Now we demonstrate how to implement cross-fitting strategy to improve both statistical power and stability of a test with the help of `Crosser`. In breif, the cross-fitting atrategy try to integrate the test result on each fold: \n",
    "\n",
    "+ When the null distribution is constructed by `resampling` method, the integration is based on Algorithm 4 of Tansey et al (2022);\n",
    "+ When the null distribution is constructed by `normality` and `permutation` method, the integration is based on Algorithm 3 of Williamson et al. (2023).\n",
    "\n",
    "In this example, the conditional predictive impact (CPI) will be used to test the significance of `sex`. Hence, a sampler for `sex` is necessary. Note that the sampler must be trained with the same cross-validator as we specified for training the learner. Otherwise, `sial` cannot perform cross-fitting correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308a4e98-6d74-4b4c-b7bc-47338a15fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "removal = \"sex\"\n",
    "sampler = Crosser(\n",
    "    GridSearchCV(\n",
    "        estimator = RandomForestClassifier(), \n",
    "        param_grid = {\n",
    "            \"max_features\": [3, 6, 9]}),\n",
    "    cv = cv)\n",
    "_ = sampler.fit(\n",
    "    X.drop(removal, axis = 1), \n",
    "    X[removal])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b09f2-3a1a-4425-96b0-e0dd814e0179",
   "metadata": {},
   "source": [
    "To implement cross-fitting, we replace usual estimators by their corresponding `Crosser` objects when initializing the `Inferer`. The `summarize` method will integrate the results via cross-fitting by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e2e97f-2226-424d-8ae8-ba9b7f5efaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferer Summary (cross_fit=True, combine=False)\n",
      " + Method: CPI (double_split=None, perturb_size=None)\n",
      " + Null Distribution: Normality (n_copies=100, n_permutations=None)\n",
      " + Loss Function: Mean Squared Error (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>442</td>\n",
       "      <td>54.395756</td>\n",
       "      <td>17.728132</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         size   estimate  std_error   p_value\n",
       "removal                                      \n",
       "sex       442  54.395756  17.728132  0.001076"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sial.inferer import CIT\n",
    "cpi = CIT(\n",
    "    learner, \n",
    "    sampler,\n",
    "    removal,\n",
    "    \"CPI\",\n",
    "    n_copies = 100)\n",
    "_ = cpi.infer(X, y)\n",
    "cpi.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7a0f0-a681-4506-8635-89c325604be0",
   "metadata": {},
   "source": [
    "To inspect the result on each fold, we can set `cross_fit = False`. We can see that these results are unstable bacause of the small sample sizes of the `diabetes` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d90eb34-4da2-40fd-acbb-844d5dbb506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferer Summary (cross_fit=False, combine=False)\n",
      " + Method: CPI (double_split=None, perturb_size=None)\n",
      " + Null Distribution: Normality (n_copies=100, n_permutations=None)\n",
      " + Loss Function: Mean Squared Error (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removal</th>\n",
       "      <th>split</th>\n",
       "      <th>repeat</th>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sex</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>21.346994</td>\n",
       "      <td>31.760977</td>\n",
       "      <td>0.250756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>116.543331</td>\n",
       "      <td>36.613575</td>\n",
       "      <td>0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>-1.672984</td>\n",
       "      <td>35.795756</td>\n",
       "      <td>0.518639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>43.603011</td>\n",
       "      <td>44.527297</td>\n",
       "      <td>0.163730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "      <td>88</td>\n",
       "      <td>92.158430</td>\n",
       "      <td>49.508939</td>\n",
       "      <td>0.031340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           size    estimate  std_error   p_value\n",
       "removal split repeat fold                                       \n",
       "sex     0     0      0       89   21.346994  31.760977  0.250756\n",
       "        1     0      1       89  116.543331  36.613575  0.000729\n",
       "        2     0      2       88   -1.672984  35.795756  0.518639\n",
       "        3     0      3       88   43.603011  44.527297  0.163730\n",
       "        4     0      4       88   92.158430  49.508939  0.031340"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi.summarize(\n",
    "    cross_fit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7d222-17f5-4180-9dc3-17bd36868973",
   "metadata": {},
   "source": [
    "## Inference with Both Cross-Fitting and $p$-Value Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe93c9-6455-459a-a394-f3e9d69412e8",
   "metadata": {},
   "source": [
    "Another way to improve the stability of testing is using $p$-value combination. In this example, we use both cross-fitting and $p$-value combination. We plan to conduct 5-fold cross-validation four times. Hence, `RepeatedKFold` is used as a cross-validator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6b20c2-18d4-4e02-80a4-0bd82ec30a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "cv = RepeatedKFold(\n",
    "    n_splits = 5,\n",
    "    n_repeats = 4,\n",
    "    random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419c01a-0937-46cd-af4c-8604400fc334",
   "metadata": {},
   "source": [
    "In `sial`, `n_splits` is used to denote the number of all splits and the number of folds will be represented by another variable called `n_folds`. Hence, the specified `n_splits = 5` and `n_repeats = 4` in this example results in `n_splits = 20`, `n_folds = 5`, and `n_repeats = 4` stored in both `Crosser` and `Inferer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca4da99-7dc4-4f8e-8215-5dcc603f96f0",
   "metadata": {},
   "source": [
    "Then we train a learner and a sampler with the `RepeatedKFold` cross-validator and conduct CPI for `sex`. By default, the `summarize` method implement several p-value combination methods that aggregate the $p$-values obtained in the four replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bdad2-2f92-4cae-94f0-6fd51c88e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Crosser(\n",
    "    GridSearchCV(\n",
    "        estimator = RandomForestRegressor(), \n",
    "        param_grid = {\n",
    "            \"max_features\": [3, 6, 9]}),\n",
    "    cv = cv)\n",
    "sampler = Crosser(\n",
    "    GridSearchCV(\n",
    "        estimator = RandomForestClassifier(), \n",
    "        param_grid = {\n",
    "            \"max_features\": [3, 6, 9]}),\n",
    "    cv = cv)\n",
    "_ = learner.fit(X, y)\n",
    "_ = sampler.fit(\n",
    "    X.drop(removal, axis = 1), \n",
    "    X[removal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb686c5-691a-4ad6-b5c8-490938cb5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = CIT(\n",
    "    learner, \n",
    "    sampler,\n",
    "    removal,\n",
    "    \"CPI\",\n",
    "    n_copies = 100)\n",
    "_ = cpi.infer(X, y)\n",
    "cpi.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d3433-f4dc-49c4-afed-76d25020e371",
   "metadata": {},
   "source": [
    "To see the $p$-value in each replication, we can set both `combine = False` in the `summarize` method. Note that these $p$-values are calculated based on cross-fitting. Even after cross-fitting, the $p$-values still differ slightly across replications. That is why $p$-value combination could be helpful for enhencing reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784d32e-1dc5-4887-a08f-78e6ca9d29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi.summarize(\n",
    "    combine = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f788d0-f79b-443d-9b8c-222a5975b1e2",
   "metadata": {},
   "source": [
    "If users are interested in the $p$-value on each split, we can set `combine = False` and `cross_fit = False`. We can see that the split-level results are indeed unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bec9e9-9683-4855-8c57-b060e8f171e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi.summarize(\n",
    "    cross_fit = False,\n",
    "    combine = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff45db-5ac0-4976-8a72-4dbcafe1023c",
   "metadata": {},
   "source": [
    "Breifly speaking, `cross_fit` controls aggregating results over `n_folds` given a repeat and `combine` controls combining results over `n_splits`. If both `cross_fit` and `combine` are `True`, the `summarize` method first aggregates the results of folds for each replication and then do $p$-value combination based on the results made by first step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d935dc7-60cb-4746-be9d-470d408af188",
   "metadata": {},
   "source": [
    "Finally, it is possible to combine all $p$-values without doing cross-fitting first by setting `combine = True` and `cross_fit = False`. This approach might result in conservative results for some p-value combination methods. However, so far it is hard to say which method is more reliable. The relative performances of these combination methods require further empirical evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe8b1a-69f3-4ae3-bff9-8b6fa9bb9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi.summarize(\n",
    "    cross_fit = False,\n",
    "    combine = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937d88e-9e13-48fd-b19d-2b00fc3379b6",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Tansey, W., Veitch, V., Zhang, H., Rabadan, R., & Blei, D. M. (2022). The holdout randomization test for feature selection in black box models. Journal of Computational and Graphical Statistics, 31(1), 151–162. doi: 10.1080/10618600.2021.1923520\n",
    "\n",
    "Williamson, B. D., Gilbert, P. B., Simon, N. R., & Carone, M. (2023). A general framework for inference on algorithm-agnostic variable importance. Journal of the American Statistical Association, 118(543), 1645–1658. doi: 10.1080/01621459.2021.2003200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
