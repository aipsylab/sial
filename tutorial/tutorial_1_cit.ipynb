{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6f6508-c855-4786-b52e-4d255a3bad0a",
   "metadata": {},
   "source": [
    "# Tutorial 1: Conditional Independence Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ccfe2-db27-4f64-86d0-692b84f829d5",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrate how to use `sial` package to conduct conditional independence tests (CITs) for feature importance. These CITs include holdout randomization test (HRT), residual permutation test (RPT), and conditional predictive impact (CPI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70362b11-d293-456b-ad7a-cd9854f40b0f",
   "metadata": {},
   "source": [
    "To install `sial` via `pip`, please use:\n",
    "```\n",
    "pip install sial-pkg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de1cd5-7df9-4770-9ed3-b1e7b94901cf",
   "metadata": {},
   "source": [
    "## `Diabetes` Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47526c-4114-4a0d-940d-0242a042adb6",
   "metadata": {},
   "source": [
    "We use the `diabetes` data set as example for demonstration. The details of the data set can be found [here](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e5ed52-8488-4b9d-8fe9-58080cc2db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad086682-f465-461b-b410-a67fba21b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "diabetes = datasets.load_diabetes(scaled = False)\n",
    "X, y = diabetes.data, diabetes.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size = .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985bf46f-6a15-4a46-bfb2-5bbdcdf8bdab",
   "metadata": {},
   "source": [
    "We train a random forest (RF) regressor on the training set and evaluate its performance with mean squared error (MSE) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa98d453-4d78-466d-a50b-8bdde0825e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3460.9536624434395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "learner = RandomForestRegressor()\n",
    "_ = learner.fit(\n",
    "    X_train, y_train)\n",
    "print(\"MSE:\",\n",
    "      mean_squared_error(\n",
    "          y_test, \n",
    "          learner.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a977404-580b-418e-a165-d1be74ff6548",
   "metadata": {},
   "source": [
    "## CIT Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e00c2-5c84-418a-bfdb-f73673c34478",
   "metadata": {},
   "source": [
    "Let $f(x)$ denote a learner that predicts the value of $y$ based on $x=(x_1,x_2,...,x_P)$. To test the importance of $x_j$, the $j^{th}$ feature, the conditional independence tests (CITs) consider the following hypothesis testing problem:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&H_0:y \\perp x_j|x_{-j}, \\\\ \n",
    "&H_A:y \\not\\perp x_j|x_{-j},\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $x_{-j}$ is the feature vector without $x_j$. The basic idea of CITs is to compare the predictive error made by $f(x)$ and $f(x^*)$, where $x^*$ is a resampled feature vector with $x_j$ being replaced by $x_j^* \\sim \\text{Pr}(x_j|x_{-j})$. Because $x_j^*$ is independet to $y$ given $x_{-j}$, if $x_j$ is indeed important in predicting $y$, $f(x^*)$ will result in larger predictive errors than $f(x)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cceb905-f7d0-42a6-ad8f-20fc7f3079e2",
   "metadata": {},
   "source": [
    "## HRT and RPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe470b3b-256c-43fe-bc13-8555b7e63193",
   "metadata": {},
   "source": [
    "Let $Z=\\{(x_n,y_n)\\}_{n=1}^N$ denote a random sample. The holdout randomization test (HRT; Tansey et al., 2022) splits $Z$ into a training set and a test set, say $Z_\\text{train}$ and $Z_\\text{test}$. The training set is used to train $\\widehat{f}$ by minimizing an estimation criterion $D(f; Z_\\text{train})$. On the other hand, the test set is used to test the significance of $x_j$ by comparing $D(\\widehat{f}; Z_\\text{test})$ and $D(\\widehat{f}; Z_{\\text{test},j}^*)$ many times, where $Z_{\\text{test},j}^*$ is a resampled version of $Z_{\\text{test}}$.\n",
    "\n",
    "HRT can be conducted provided that a sampler is available, that is, a full probabilistic model for $x_j$ given $x_{-j}$ (i.e., $\\widehat{\\text{Pr}}(x_j|x_{-j})$). However, most ML algorithms only estimate a mean function for $x_j$ given $x_{-j}$ (i.e., $\\widehat{\\text{E}}(x_j|x_{-j})$), which is not sufficient for generate $x_j^*$ if $x_j$ is numeric. Hence, for a numeric $x_j$, the residual permutation test (RPT; Huang, 2024) considers an auxliary model $x_j=h_j(x_{-j})+\\delta_j$ and generates each $x_{nj}^*$ by\n",
    "$$\n",
    "x_{nj}^* = \\widehat{h}_j(x_{n,-j}) + \\text{permute}(\\widehat{\\delta}_{nj}),\n",
    "$$\n",
    "where $\\widehat{h}_j$ is trained on $Z_\\text{train}$, $\\widehat{\\delta}_{nj}$ is an empirical residual, and $\\text{permute}(\\cdot)$ is a permutation operator. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7143bb-60e2-41c1-abb3-413f7e909c80",
   "metadata": {},
   "source": [
    "Now, we use the diabetes data set to demonstrate how to conduct RPT. To evaluate the significance of `bmi`, we train a `sampler` for `bmi` given other features. Note that the `sampler` is not necessarily to be learned based on the same algorithm for obtaining the learner. However, its quality might influence the performance of RPT. Our experience shows that RF is a good choice (Huang, 2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a677fcb-6bf8-4b08-98ba-f5d1cb3ba99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "removal = 2\n",
    "sampler = RandomForestRegressor()\n",
    "_ = sampler.fit(\n",
    "    np.delete(X_train, removal, axis = 1), \n",
    "    X_train[:, removal])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a987d3e7-d29f-4c63-9066-17d297d43e23",
   "metadata": {},
   "source": [
    "Note that `removal = 2` is the column index of `bmi`. Because `X` is a numpy array here, `removal` must be the column index of the feature being inferred. In other examples, we will see that `removal` will be the column name of $x_j$ when `X` is `DataFrame`. The correspondence between column index and column name can be shown as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe3a15e-8ba6-49a0-9c05-621e4d07f7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'age',\n",
       " 1: 'sex',\n",
       " 2: 'bmi',\n",
       " 3: 'bp',\n",
       " 4: 's1',\n",
       " 5: 's2',\n",
       " 6: 's3',\n",
       " 7: 's4',\n",
       " 8: 's5',\n",
       " 9: 's6'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{index:name for index, name in enumerate(diabetes.feature_names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a59da1-344c-4511-8373-f726dd0b4250",
   "metadata": {},
   "source": [
    "In `sial`, the `CIT` object can be used to conduct RPT if we set `method` to `\"RPT\"`. By default, `CIT` uses MSE as loss function to evaluate the predictive error for regression tasks. The type of loss function can be explicitly sepcified via `loss_func` argumant. In the current version, only `\"mean_squared_error\"` and `\"mean_absolute_error\"` are supported for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38586649-aa83-4f2f-baba-7cd35c346cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sial import CIT\n",
    "rpt = CIT(\n",
    "    learner, \n",
    "    sampler = sampler,\n",
    "    removal = removal,\n",
    "    method = \"RPT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56ca6e-6f60-46f8-9c46-b121e10eab58",
   "metadata": {},
   "source": [
    "Finally, we use the `infer` method to conduct hypothesis testing. Both HRT and RPT construct a null distribution by using resampling technique, which can be explicitly specified by `null_dist = \"resampling\"`. The number of resampling samples can be set via `n_copies` argument. By default, `n_copies = 2000`. The inference result can be then summarized via the `summarize` method. The `estimate` in the output table can be interpretated as a conditional permutation feature importance (CPFI) for `bmi`. The larger CPFI means that the `bmi` is more important in reducing the value of MSE. The significance of `bmi` can be determined by the $p$-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26d1b01-d893-497c-9a00-a9d1ad16eed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferer Summary (cross_fit=False, combine=False)\n",
      " + Method: RPT (double_split=None, perturb_size=None)\n",
      " + Null Distribution: Resampling (n_copies=2000, n_permutations=None)\n",
      " + Loss Function: Mean Squared Error (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>1025.975402</td>\n",
       "      <td>275.858725</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         size     estimate   std_error  p_value\n",
       "removal                                        \n",
       "2         221  1025.975402  275.858725      0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = rpt.infer(X_test, y_test)\n",
    "rpt.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef345e-2621-49e0-aae4-60c9e162ae96",
   "metadata": {},
   "source": [
    "## CPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e77546-6902-4ae1-8a9f-6972332e45c1",
   "metadata": {},
   "source": [
    "The conditional predictive impact (CPI; Watson & Wright, 2021) is another CIT. The CPI is proposed under the knockoff framework (Barber & Candès, 2015). However, if we only consider the significance of $x_j$, $x_j^* \\sim \\text{Pr}(x_j|x_{-j})$ can be regarded as a knockoff of $x_j$. Standard CPI also evaluates the difference between $D(\\widehat{f}; Z_\\text{test})$ and $D(\\widehat{f}; Z_{\\text{test},j}^*)$ but just one time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738d3400-e7da-428d-932a-819a33521e04",
   "metadata": {},
   "source": [
    "Now, we use CPI to evlauate the significance of `sex` in the diabetes data set. Because `sex` is a categorical feature, we train a sampler for it by using a RF classifier. Then $x_j^*$ can be easily sampled by using the `predict_proba` method (which will be done inside the `infer` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2145ece2-273b-4bba-b2bf-de5ca23c55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "removal = 1\n",
    "sampler = RandomForestClassifier()\n",
    "_ = sampler.fit(\n",
    "    np.delete(X_train, removal, axis = 1), \n",
    "    X_train[:, removal])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dcd89b-531f-4052-aa66-8663a2c9a1b8",
   "metadata": {},
   "source": [
    "An inferer for CPI can be constructed by using `CIT` with `method = \"CPI\"`. Unlike HRT and RPT, by default the CPI only generates one copy of $x_j^*$ (`n_copies = 1`) and uses normal approximation for the null distribution (`null_dist = \"normality\"`). As a result, CPI is much faster than HRT and RPT. Another choice here is permutation that constructs the null distribution by using a permutation technique (`null_dist = \"permutation\"`). The number of permutations can be specified via `n_permutations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdfe4743-3b6f-4f13-a7bf-214f80711d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferer Summary (cross_fit=False, combine=False)\n",
      " + Method: CPI (double_split=None, perturb_size=None)\n",
      " + Null Distribution: Normality (n_copies=1, n_permutations=None)\n",
      " + Loss Function: Mean Squared Error (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>12.936254</td>\n",
       "      <td>19.243884</td>\n",
       "      <td>0.25072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         size   estimate  std_error  p_value\n",
       "removal                                     \n",
       "1         221  12.936254  19.243884  0.25072"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi = CIT(\n",
    "    learner, \n",
    "    sampler,\n",
    "    removal,\n",
    "    \"CPI\")\n",
    "_ = cpi.infer(X_test, y_test)\n",
    "cpi.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1662ad1-103b-4691-aa2d-f34060c30ca3",
   "metadata": {},
   "source": [
    "CPI only generate one copy of $x_j^*$ to calculate its test statistic. Hence, it might be unstable under small sample sizes. A way to improve its stability is to generate more copies for approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b18efc21-b4af-463d-a42e-97e4dc21b948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferer Summary (cross_fit=False, combine=False)\n",
      " + Method: CPI (double_split=None, perturb_size=None)\n",
      " + Null Distribution: Normality (n_copies=100, n_permutations=None)\n",
      " + Loss Function: Mean Squared Error (reverse=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>estimate</th>\n",
       "      <th>std_error</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "      <td>9.185257</td>\n",
       "      <td>11.816376</td>\n",
       "      <td>0.218481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         size  estimate  std_error   p_value\n",
       "removal                                     \n",
       "1         221  9.185257  11.816376  0.218481"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi = CIT(\n",
    "    learner, \n",
    "    sampler,\n",
    "    removal,\n",
    "    \"CPI\",\n",
    "    n_copies = 100)\n",
    "_ = cpi.infer(X_test, y_test)\n",
    "cpi.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfb241-ac1f-4eed-a824-e50380be90eb",
   "metadata": {},
   "source": [
    "The `std_error` shows that increasing the number of copies would be helpful. However, using more copies results in larger computation time. The tradeoff between accuracy and computation time is always an important issue when using ML. At least, for a relatively small data set, we recommend using more copies to improve stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39af0b-e183-4a41-816a-85f34b325a7c",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Barber, R. F., & Candès, E. J. (2015). Controlling the false discovery rate via knockoffs. The Annals of Statistics, 43(5), 2055 – 2085. doi: 10.1214/15-AOS1337\n",
    "\n",
    "Huang, P.-H. (2024). Residual Permutation Tests for Feature Importance in Machine Learning. [Manuscript submitted for publication].\n",
    "\n",
    "Tansey, W., Veitch, V., Zhang, H., Rabadan, R., & Blei, D. M. (2022). The holdout randomization test for feature selection in black box models. Journal of Computational and Graphical Statistics, 31(1), 151–162. doi: 10.1080/10618600.2021.1923520\n",
    "\n",
    "Watson, D., & Wright, M. (2021). Testing conditional independence in supervised learning algorithms. Machine Learning, 110, 1-23. doi: 10.1007/s10994-021-06030-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
